{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvYQ7p8sQ8Bk4524Pvf7EU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"dcGLoMICQ36q"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn  # Importing the nn module\n","\n","class Transformer(nn.Module):  # Now this should work\n","    def __init__(self, encoder, decoder):\n","        super(Transformer, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n"],"metadata":{"id":"P7EqLuQiTP6m","executionInfo":{"status":"ok","timestamp":1732000945235,"user_tz":-540,"elapsed":3798,"user":{"displayName":"조민진","userId":"10146282544826153090"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ayr9i-cpKTXq","executionInfo":{"status":"ok","timestamp":1732000955031,"user_tz":-540,"elapsed":301,"user":{"displayName":"조민진","userId":"10146282544826153090"}}},"outputs":[],"source":["class Transformer(nn.Module):\n","\n","  def __init__(self, encoder, decoder):\n","    super(Transformer, self).__init__()\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def encode(self, x):\n","    out = self.encoder(x)\n","    return out\n","\n","  def decode(self, z, c):\n","    out = self.decode(z, c)\n","    return out\n","\n","  def forward(self, x, z):\n","    c = self.encode(x)\n","    y = self.decode(z, c)\n","    return y"]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","\n","  def __init__(self, encoder_block, n_layer): #n_layer: Encoder Block의 개수\n","    super(Encoder, self).__init__()\n","    self.layers = []\n","    for i in range(n_layer):\n","      self.layers.append(copy.deepcopy(encoder_block))\n","\n","  def forward(self, x):\n","    out = x\n","    for layer in self.layers:\n","      out = layer(out)\n","    return out"],"metadata":{"id":"Eb4Ar8lfTdBV","executionInfo":{"status":"ok","timestamp":1732002342608,"user_tz":-540,"elapsed":283,"user":{"displayName":"조민진","userId":"10146282544826153090"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class EncoderBlock(nn.Module):\n","  def __init__(self, self_attention, position_ff):\n","    super(EncoderBlock, self).__init__()\n","    self.self_attention = self_attention\n","    self.position_ff = position_ff\n","  def forward(self, x):\n","    out = x\n","    out = self.self_attention(out)\n","    out = self.position_ff(out)\n","    return out"],"metadata":{"id":"nZYQgs3oYn-l","executionInfo":{"status":"ok","timestamp":1732002657233,"user_tz":-540,"elapsed":274,"user":{"displayName":"조민진","userId":"10146282544826153090"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def calculate_attention(query, key, value, mask):\n","  #query, key, value: (n_batch, seq_len, d_k)\n","  #mask: (n_batch, seq_len, seq_len)\n","  d_k = key.shape[-1]\n","  attention_score = torch.matmul(query, key.transpose(-2, -1)) # Q x K^T, (n_batch, seq_len, seq_len)\n","  attention_score = attention_score / math.squr(d_k)\n","  if mask is not None:\n","    attention_score = attention_score.masked_fill(mask==0, -1e9)\n","  attention_prob = F.softmax(attention_score, dim = -1) #(n_batch, seq_len, seq_len)\n","  out = torch.matmul(attention_prob, value) #(n_batch, seq_len, d_k)\n","  return out"],"metadata":{"id":"9uZS4sZgY2PJ","executionInfo":{"status":"ok","timestamp":1732002658235,"user_tz":-540,"elapsed":3,"user":{"displayName":"조민진","userId":"10146282544826153090"}}},"execution_count":12,"outputs":[]}]}